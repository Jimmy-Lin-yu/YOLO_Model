import os
import time
import glob
import yaml
import torch
import random
import subprocess
from datetime import datetime
from ultralytics import YOLO

# os.environ["TORCH_FORCE_DISABLE_INFERENCE_MODE"] = "1"   # é¿å… Ultralytics è‡ªå‹•å•Ÿç”¨ inference_mode

# ---------- å…¬ç”¨ï¼šè¨ˆæ™‚å™¨ ----------
def run_with_timer(description, func, *args, log_file_path=None, **kwargs):
    start_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"ğŸŸ¢ [{description}] é–‹å§‹æ™‚é–“ï¼š{start_time_str}")
    t0 = time.time()
    result = func(*args, **kwargs)
    t1 = time.time()
    end_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    minutes, seconds = divmod(int(t1 - t0), 60)
    time_used = f"{minutes} åˆ† {seconds} ç§’"
    print(f"âœ… [{description}] çµæŸæ™‚é–“ï¼š{end_time_str}")
    print(f"â±ï¸ ç¸½å…±èŠ±è²»æ™‚é–“ï¼š{time_used}\n")

    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    if not log_file_path:
        log_file_path = os.path.join(log_dir, f"{datetime.now().strftime('%Y-%m-%d')}.log")
    with open(log_file_path, 'a', encoding="utf-8") as f:
        f.write(f"[{description}]\né–‹å§‹æ™‚é–“ï¼š{start_time_str}\nçµæŸæ™‚é–“ï¼š{end_time_str}\nç¸½å…±èŠ±è²»æ™‚é–“ï¼š{time_used}\n")
        f.write("-" * 40 + "\n")
    return result

# ---------- å¯é‡ç¾æ€§ ----------
def set_seed(seed: int = 42):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"ğŸ”’ å·²è¨­å®š random seed = {seed}ï¼ˆcudnn deterministic=Trueï¼‰")

# ---------- ä¾è³´ï¼šå…ˆç¢ºä¿ pycocotools å­˜åœ¨ ----------
def ensure_pycocotools():
    try:
        import pycocotools  # noqa: F401
        print("âœ… å·²å®‰è£ pycocotools")
    except Exception:
        print("ğŸ“¦ å®‰è£ pycocotools ä¸­â€¦")
        subprocess.run(
            ["python3", "-m", "pip", "install", "-q", "pycocotools>=2.0.6"],
            check=True
        )
        print("âœ… pycocotools å®‰è£å®Œæˆ")

# ---------- è³‡æ–™/è¨­å®šå¥æª¢ ----------
def assert_no_background_class(dataset_yaml_path: str):
    with open(dataset_yaml_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)
    names = cfg.get("names")
    if isinstance(names, dict):
        name_list = [names[k] for k in sorted(names.keys())]
    else:
        name_list = list(names)
    lowered = [str(n).strip().lower() for n in name_list]
    forbidden = {"background", "bg", "ok"}
    hit = [n for n in lowered if n in forbidden]
    if hit:
        raise ValueError(
            f"âŒ dataset.yaml çš„ names å…§å«ä¸æ‡‰å­˜åœ¨çš„é¡åˆ¥ï¼š{hit}\n"
            f"è«‹åˆªé™¤ background/okï¼Œåƒ…ä¿ç•™ç¼ºé™·é¡ï¼ˆä¾‹å¦‚ï¼š['NG']ï¼‰ã€‚\n"
            f"OK å½±åƒæ‡‰è©²æ²’æœ‰ label æª”ã€‚"
        )
    print(f"âœ… å·²æª¢æŸ¥ dataset.yamlï¼šnames = {name_list}ï¼ˆæœªåŒ…å« background/okï¼‰")

def quick_dataset_sanity(dataset_yaml_path: str):
    with open(dataset_yaml_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)
    base = cfg.get("path", "")
    train_rel = cfg.get("train")
    val_rel = cfg.get("val") or cfg.get("validation") or cfg.get("val_dir")

    def _count_pair(img_dir_rel):
        img_dir = os.path.join(base, img_dir_rel)
        lbl_dir = img_dir.replace(os.sep + "images", os.sep + "labels")
        img_paths = sorted(glob.glob(os.path.join(img_dir, "*.*")))
        n_img = len(img_paths)
        n_with_lbl = 0
        n_without_lbl = 0
        for p in img_paths:
            stem = os.path.splitext(os.path.basename(p))[0]
            lp = os.path.join(lbl_dir, stem + ".txt")
            if os.path.exists(lp) and os.path.getsize(lp) > 0:
                n_with_lbl += 1
            else:
                n_without_lbl += 1
        return n_img, n_with_lbl, n_without_lbl

    for split in [("train", train_rel), ("val", val_rel)]:
        if split[1]:
            n_img, n_with, n_without = _count_pair(split[1])
            print(f"ğŸ“¦ {split[0]}ï¼šç¸½å½±åƒ {n_img}ï½œæœ‰æ¨™è¨»(NG) {n_with} ï½œç„¡æ¨™è¨»(OK) {n_without}")
    print("ğŸ’¡ ç„¡æ¨™è¨»å½±åƒå³ç‚º OKï¼ˆå½±åƒç­‰ç´šç‚º OKï¼‰ã€‚")

# ---------- ä¸»æµç¨‹ ----------
def main():
    # è£ç½®èˆ‡ç¨®å­
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"Using device: {'cuda:0' if device==0 else 'cpu'}")
    set_seed(42)

    # å¯èª¿åƒæ•¸
    dataset_yaml = "/app/dataset/YOLO_seg/dataset.yaml"
    epochs = 250
    imgsz = 1024
    conf = 0.03
    iou = 0.45

    # ä¾è³´ & å¥æª¢
    ensure_pycocotools()
    assert os.path.isfile(dataset_yaml), f"æ‰¾ä¸åˆ° dataset.yamlï¼š{dataset_yaml}"
    assert_no_background_class(dataset_yaml)
    quick_dataset_sanity(dataset_yaml)

    # æ¨¡å‹ï¼ˆç”¨é è¨“ç·´æ¬Šé‡ï¼‰
    model = YOLO("yolo11s-seg.pt")

    # è¨“ç·´
    run_with_timer(
        "è¨“ç·´ yolo11s-seg.pt æ¨¡å‹",
        model.train,
        data=dataset_yaml,
        epochs=epochs,
        imgsz=imgsz,
        batch=-1,
        device=0,
        project="seg_runs",
        name="y11sseg_V2_251203",
        # mosaic=1.0, mixup=0.0, close_mosaic=10,
        # translate=0.2, scale=0.5, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,
        verbose=True
    )

if __name__ == "__main__":
    main()
